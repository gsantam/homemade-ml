{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decission trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decission tress is an algorithm used for both regression and classification which is super easy to interpret since can be encoded as a chain of `IF` `ELSE` statements over the predictor variables. \n",
    "Given a collection of labeled examples, $(X,Y)$, where $X = X_1 \\times X_2 \\times \\dotso \\times X_m$, the decission tress algorithm can be summarized in two steps:\n",
    "- Divide the predictor space $X$ into $J$ different non-overlapping regions $R= \\{R_{1},R_{2},\\dotso, R_{j}\\}$\n",
    "- For a region $R_{i}$, let $(X_{R_{i}},Y_{R_{i}}) \\subset (X,Y)$ be all the labeled observations such that $x_{R_{i}}$ falls in $R_{i}$. Then, given a $x\\in R_{i}$:\n",
    "    - If we are doing regression, we will predict the label of $x$ with the mean of $Y_{R_{i}}$\n",
    "    - If we are doing classification we will predict the label of $x$  with the majority class in $Y_{R_{i}}$ \n",
    "\n",
    "For example, if the step one divides the space into two regions $R_{1}$ and $R_{2}$ and the mean of the labels of the samples in  $R_{1}$ is 10 and the mean of the labels of the samples in $R_{2}$ is 30, we will predict 10 is $x\\in R_{1}$, otherwise 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "### The minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with linear regression, we are going to find a function $f_{R}$ which minimizes the quadratic error $L(R) = \\frac{1}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{R}(x) - y)^{2}$ of the predictions. The tricky thing here is of course how do we find $R$, the non-overlapping regions of $X$.\n",
    "For this, we are going to use a *recursive greedy* approach where, at each step, we are going to select one of the variables in $X$ and we are going to split it in two parts based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston,load_iris,load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "X = boston_dataset[\"data\"]\n",
    "y = boston_dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cut_for_mse = {}\n",
    "for i in range(X.shape[1]):\n",
    "    x_var = X[:,i]\n",
    "    best_mse = 10**10\n",
    "    best_cut = None\n",
    "    for x in x_var:\n",
    "        mean_y_under_x = np.mean(y[x_var<x])\n",
    "        mean_y_over_x = np.mean(y[x_var>=x])\n",
    "        sse = np.sum((y[x_var<x] - mean_y_under_x)**2) + np.sum((y[x_var>=x] - mean_y_over_x)**2)\n",
    "        mse = (1/len(y))*sse\n",
    "        if mse<=best_mse:\n",
    "            best_mse = mse\n",
    "            best_cut = x\n",
    "            best_cut_for_mse[i] = [best_mse,best_cut,mean_y_under_x,mean_y_over_x]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "    def __init__(self,X,y,max_depth,depth = 0,mean_y = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.leaf = False\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.mean_y = mean_y\n",
    "        \n",
    "    def fit(self):\n",
    "        if not (self.X.shape[0]>0 and self.X.shape[1]>0 and self.depth<self.max_depth):\n",
    "            self.leaf = True\n",
    "            return \n",
    "            \n",
    "        best_cut = self.get_best_predictor_with_cut()\n",
    "        self.predictor_idx = best_cut[0]\n",
    "        self.cut = best_cut[1]\n",
    "        self.mean_y_under_cut = best_cut[2]\n",
    "        self.mean_y_over_cut = best_cut[3]\n",
    "        predictor = self.X[:,self.predictor_idx]\n",
    "        \n",
    "        X_left = self.X[predictor<self.cut,:]\n",
    "        y_left = self.y[predictor<self.cut]\n",
    "        #X_left = np.delete(X_left,self.predictor_idx,axis = 1)  \n",
    "        self.left_node = TreeNode(X_left,y_left,self.max_depth,self.depth + 1,self.mean_y_under_cut)\n",
    "        self.left_node.fit()\n",
    "    \n",
    "        X_right = self.X[predictor>=self.cut,:]\n",
    "        y_right = self.y[predictor>=self.cut]\n",
    "        #X_right = np.delete(X_right,self.predictor_idx,axis = 1)  \n",
    "        self.right_node = TreeNode(X_right,y_right,self.max_depth,self.depth + 1,self.mean_y_over_cut)\n",
    "        self.right_node.fit()\n",
    "            \n",
    "    def predict(self,X):\n",
    "        y_s = []\n",
    "        for x in X:\n",
    "            y_s.append(self.predict_(x))\n",
    "        return np.asarray(y_s)\n",
    "        \n",
    "    def predict_(self,x):\n",
    "        if self.leaf:\n",
    "            return self.mean_y\n",
    "        else:\n",
    "            value_at_predictor = x[self.predictor_idx]\n",
    "            #x_without_predictor = np.delete(x,self.predictor_idx,axis = 0)\n",
    "            x_without_predictor = x\n",
    "            if value_at_predictor < self.cut:\n",
    "                return self.left_node.predict_(x_without_predictor)\n",
    "            else:\n",
    "                return self.right_node.predict_(x_without_predictor)\n",
    "        \n",
    "    def get_best_predictor_with_cut(self):\n",
    "\n",
    "        best_mse = 10**10\n",
    "        for predictor_idx in range(self.X.shape[1]):\n",
    "            best_mse_of_predictor = 10**10\n",
    "            predictor = self.X[:,predictor_idx]\n",
    "            for cut in predictor:\n",
    "                mean_y_under_cut = np.mean(self.y[predictor<cut])\n",
    "                mean_y_over_cut = np.mean(self.y[predictor>=cut])\n",
    "                sse = np.sum((self.y[predictor<cut] - mean_y_under_cut)**2) + np.sum((self.y[predictor>=cut] - mean_y_over_cut)**2)\n",
    "                mse = (1/len(self.y))*sse\n",
    "                if mse<=best_mse_of_predictor:\n",
    "                    best_mse_of_predictor = mse\n",
    "                    best_cut_of_predictor = [predictor_idx,cut,mean_y_under_cut,mean_y_over_cut]\n",
    "                    \n",
    "            if best_mse_of_predictor<best_mse:\n",
    "                best_mse = best_mse_of_predictor \n",
    "                best_cut = best_cut_of_predictor\n",
    "                    \n",
    "        return best_cut\n",
    "    \n",
    "    def get_error(self):\n",
    "        if self.leaf:\n",
    "            return np.sum((self.mean_y - self.y)**2)\n",
    "        else:\n",
    "            return self.left_node.get_error() + self.right_node.get_error()\n",
    "                \n",
    "\n",
    "model = TreeNode(X,y,4)\n",
    "model.fit()\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880.779104426192"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880.779104426193"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(y - tree.predict(X),y - tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=4, random_state=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(random_state = 0,max_depth = 4)\n",
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880.779104426193"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(y - tree.predict(X),y - tree.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_dataset = load_breast_cancer()\n",
    "X = breast_cancer_dataset[\"data\"]\n",
    "y = breast_cancer_dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def compute_entropy(props):\n",
    "    entropy = 0\n",
    "    for prop in props:\n",
    "        entropy-=props[prop]*math.log(props[prop])\n",
    "    return entropy\n",
    "\n",
    "\n",
    "class TreeNode():\n",
    "    def __init__(self,X,y,max_depth,depth = 0,mean_y = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.leaf = False\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.mean_y = mean_y\n",
    "        \n",
    "    def fit(self):\n",
    "        if not (self.X.shape[0]>0 and self.X.shape[1]>0 and self.depth<self.max_depth):\n",
    "            self.leaf = True\n",
    "            return \n",
    "            \n",
    "        best_cut = self.get_best_predictor_with_cut()\n",
    "        self.predictor_idx = best_cut[0]\n",
    "        self.cut = best_cut[1]\n",
    "        self.mean_y_under_cut = best_cut[2]\n",
    "        self.mean_y_over_cut = best_cut[3]\n",
    "        predictor = self.X[:,self.predictor_idx]\n",
    "        \n",
    "        X_left = self.X[predictor<self.cut,:]\n",
    "        y_left = self.y[predictor<self.cut]\n",
    "        #X_left = np.delete(X_left,self.predictor_idx,axis = 1)  \n",
    "        self.left_node = TreeNode(X_left,y_left,self.max_depth,self.depth + 1,self.mean_y_under_cut)\n",
    "        self.left_node.fit()\n",
    "    \n",
    "        X_right = self.X[predictor>=self.cut,:]\n",
    "        y_right = self.y[predictor>=self.cut]\n",
    "        #X_right = np.delete(X_right,self.predictor_idx,axis = 1)  \n",
    "        self.right_node = TreeNode(X_right,y_right,self.max_depth,self.depth + 1,self.mean_y_over_cut)\n",
    "        self.right_node.fit()\n",
    "            \n",
    "    def predict(self,X):\n",
    "        y_s = []\n",
    "        for x in X:\n",
    "            y_s.append(self.predict_(x))\n",
    "        return np.asarray(y_s)\n",
    "        \n",
    "    def predict_(self,x):\n",
    "        if self.leaf:\n",
    "            return self.mean_y\n",
    "        else:\n",
    "            value_at_predictor = x[self.predictor_idx]\n",
    "            #x_without_predictor = np.delete(x,self.predictor_idx,axis = 0)\n",
    "            x_without_predictor = x\n",
    "            if value_at_predictor < self.cut:\n",
    "                return self.left_node.predict_(x_without_predictor)\n",
    "            else:\n",
    "                return self.right_node.predict_(x_without_predictor)\n",
    "        \n",
    "    def get_best_predictor_with_cut(self):\n",
    "\n",
    "        best_entropy = 10**10\n",
    "        for predictor_idx in range(self.X.shape[1]):\n",
    "            best_entropy_of_predictor = 10**10\n",
    "            predictor = self.X[:,predictor_idx]\n",
    "            for cut in predictor:\n",
    "                prop_y_under_cut = Counter(self.y[predictor<cut])\n",
    "                prop_y_over_cut = Counter(self.y[predictor>=cut])\n",
    "                prop_y_under_cut = {x:prop_y_under_cut[x]/len(self.y[predictor<cut]) for x in prop_y_under_cut}\n",
    "                prop_y_over_cut = {x:prop_y_over_cut[x]/len(self.y[predictor>=cut]) for x in prop_y_over_cut}\n",
    "                entropy = 0\n",
    "                if len(self.y[predictor<cut])>0:\n",
    "                    entropy += compute_entropy(prop_y_under_cut)*(len(self.y[predictor<cut])/len(self.y) ) \n",
    "                if len(self.y[predictor>=cut])>0:\n",
    "                    entropy += compute_entropy(prop_y_over_cut)*(len(self.y[predictor>=cut])/len(self.y) ) \n",
    "                \n",
    "                if entropy<=best_entropy_of_predictor:\n",
    "                    best_entropy_of_predictor = entropy\n",
    "                    best_cut_of_predictor = [predictor_idx,cut,prop_y_under_cut,prop_y_over_cut]\n",
    "                    \n",
    "            if best_entropy_of_predictor<best_entropy:\n",
    "                best_entropy = best_entropy_of_predictor \n",
    "                best_cut = best_cut_of_predictor\n",
    "                    \n",
    "        return best_cut\n",
    "    \n",
    "    def get_error(self):\n",
    "        if self.leaf:\n",
    "            return np.sum((self.mean_y - self.y)**2)\n",
    "        else:\n",
    "            return self.left_node.get_error() + self.right_node.get_error()\n",
    "                \n",
    "\n",
    "model = TreeNode(X,y,4)\n",
    "model.fit()\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 0.8, 1: 0.2}, {0: 1.0},\n",
       "       {0: 0.8, 1: 0.2}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 0.8, 1: 0.2}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 0.8, 1: 0.2}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 0.8, 1: 0.2},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {0: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {1: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0}, {1: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855}, {1: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0}, {0: 1.0},\n",
       "       {1: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {0: 0.5714285714285714, 1: 0.42857142857142855},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {1: 1.0}, {1: 1.0}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {1: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {1: 1.0}, {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {1: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}, {0: 1.0},\n",
       "       {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0}, {0: 1.0},\n",
       "       {0: 0.047619047619047616, 1: 0.9523809523809523}], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state = 0,max_depth = 4,criterion = \"entropy\") \n",
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.57142857, 0.42857143],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_proba(X,)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36786104643292994"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "((n-1)**n)/(n**n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    rec_n1 = rec(n-1)\n",
    "    return (rec_n1**2)/n + (rec_n1+1)*((n-rec_n1)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return ((n-1)*rec(n-1))/n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.5"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
