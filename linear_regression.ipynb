{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the most popular regressions algorithms around the world. It learns a model which is a linear combination of features of the input example. \n",
    "\n",
    "Given a colection of labeled examples $(X,Y)$, let $x$ be a feature vector of the collection, and therefore we can write $x = (x_{1},\\dots, x_{m})$ and let $y$ be the label of that example. Then, linear regression finds a vector of weights $w = (w_{1},\\dots, w_{m})$ and a bias $b$, such that, if $f_{w,b}(x) = \\sum_{1}^{n} x_{i}w_{i} + b$, these weights and bias minimize $L(w,b) = \\frac{1}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{w,b}(x) - y)^{2}$, also called the square error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $L(w,b) = \\frac{1}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{w,b}(x) - y)^{2}$ is differentiable on $w$ and $b$ because it is a sum of differentiable functions. Furthermore, one can see that is convex and therefore each local minimum is global. Therefore we are in the conditions of applying the gradient descent algorithm to find a local minimum with respect to $w$ and $b$ which will be global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the following derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial L(w,b)}{\\partial w_{i}} = \\frac{2}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{w,b}(x) - y)x_{i} $\n",
    "\n",
    "and \n",
    "\n",
    "$\\frac{\\partial L(w,b)}{b} = \\frac{2}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{w,b}(x) - y) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the gradient of $L(w,b)$ is just:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla L(w,b) = \\frac{2}{|X|}\\sum_{(x,y)\\in (X,Y)} (f_{w,b}(x) - y)(x_{1},\\dotso,x_{n},1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = boston_dataset[\"data\"]\n",
    "Y = boston_dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dL(w):\n",
    "    for i in range(X.shape[0]):\n",
    "        f_w_b = b\n",
    "        for j in range(X.shape[1]):\n",
    "            f_w_b += X[i][j]*w[j]\n",
    "        f_w_b = f_w_b - Y[i]\n",
    "    f_w_b = f_w_b*(2/X.shape[0])\n",
    "    return f_w_b*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda *w: w*[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98f89c00860e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-410d0a57fdcf>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*w)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "f(1,2,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
